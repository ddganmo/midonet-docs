[[midolman]]
= Monitoring Midolman Agents

MidoNet Agents expose a set of internal metrics that you can use to monitor the
performance and health of agent nodes.

These metrics are available using JMX in the `metrics` domain. The name of each
JMX MBean is prefixed by `org.midonet.midolman.monitoring.metrics`. To access a
particular metric, prepend the above prefix to the metric names listed below.
For example, the full name of a JMX metric is:

[source]
metrics:name=org.midonet.midolman.monitoring.metrics.DatapathMeter.flows.created

Additionally, some graphs are provided to monitor the state of the JVM running
the MidoNet Agent.

== Datapath Metrics

These metrics include meters for the created and deleted datapath flows, and
errors that occur while changing these flows.

[width="100%",cols="30%,70%",options="header",]
|=======================================================================
|Name |Description
|`DatapathMeter.flows.created`
|A meter for the created datapath flows.
|`DatapathMeter.flows.createErrors`
|A meter for the errors occurring during the creation of a datapath flow.
|`DatapathMeter.flows.createDupeErrors`
|A meter for the errors occurring during the creation of a duplicate
datapath flow.
|`DatapathMeter.flows.deleted`
|A meter for the deleted datapath flows.
|`DatapathMeter.flows.deleteErrors`
|A meter for the errors occurring during the deletion of a datapath flow.
|=======================================================================

== Netlink Metrics

These metrics include meters for Netlink messages.

[width="100%",cols="30%,70%",options="header",]
|=======================================================================
|Name |Description
|`NetlinkMeter.notifications`
|A meter for the notifications received from the OVS datapath via
Netlink.
|`NetlinkMeter.errors`
|A meter for the errors received from the OVS datapath via Netlink.
|`NetlinkMeter.htbDrops`
|A meter for the packets dropped because of the MidoNet Agent rate
limiting mechanism.
|=======================================================================

== Packet Pipeline Metrics

These metrics expose counters and meters for the simulation packet pipeline.
The MidoNet Agent exposes certain metrics for each packet worker, where the
worker index is included in the metric name. For example, when configuring
MidoNet to use two (2) packet workers, the following distinct metrics are
available: `PacketPipelineHistogram.worker-0.packetsProcessed` and
`PacketPipelineHistogram.worker-1.packetsProcessed`.

*Global Metrics*

[width="100%",cols="30%,70%",options="header",]
|=======================================================================
|Name |Description
|`PacketPipelineCounter.contextsAllocated`
|The number of allocated packet context. A packet context is an internal
variable that tracks the simulation progress for a packet that is being
processed. Since each packet context requires a certain amount of memory,
the counter reflects the memory consumption of the MidoNet agent when
processing the user-space packets.
|`PacketPipelineCounter.contextsPooled`
|The number of packet contexts that have been pooled to be reused on
subsequent packets.
|`PacketPipelineCounter.contextsBeingProcessed`
|The number of packet contexts corresponding to packets that are
currently simulated in the pipeline.
|=======================================================================

*Packet Worker Metrics*

[width="100%",cols="30%,70%",options="header",]
|=======================================================================
|Name |Description
|`PacketPipelineCounter.worker-{id}.packetsOnHold`
|The number of packets on hold, that are waiting for the agent to
read the virtual topology data from the Network State Database.
|`PacketPipelineMeter.worker-{id}.packetsPostponed`
|A meter for the packets that were postponed because their corresponding
virtual topology devices was not yet available at the agent.
|`PacketPipelineMeter.worker-{id}.packetsDropped`
|A meter for the packets dropped during simulation. These packets are
dropped because the current virtual topology does not allow them to
reach their intended destination.
|`PacketPipelineHistogram.worker-{id}.packetsProcessed`
|A histogram for the simulation latency of the processed packets. This
value is fundamental for network latency.
|`PacketPipelineHistogram.executor-{id}.packetsExecuted`
|A histogram for the packet execution latency, which includes sending back
a processed packet to the OVS datapath.
|`PacketPipelineMeter.worker-{id}.statePacketsProcessed`
|A meter for the processed packets that carried flow state data.
|`PacketPipelineMeter.worker-{id}.packetQueue.overflow`
|A meter for the packet queue overflows.
|`FlowTablesGauge.worker-{id}.currentDatapathFlows`
|A gauge for the current datapath flows.
|`FlowTablesMeter.worker-{id}.datapathFlowsCreated`
|A meter for created datapath flows.
|`FlowTablesMeter.worker-{id}.datapathFlowsRemoved`
|A meter for removed datapath flows.
|=======================================================================

== Topology Metrics

The metrics measure the virtual topology cached by a given MidoNet Agent. The
virtual topology consists of virtual devices, such as bridges, routers, ports,
chains, rules, etc. When a device is requested in order to process a packet
that must traverse or otherwise requires that device, the MidoNet Agent loads
the device from the Network State Database, and caches it for later usage. In
addition, the agent keeps a notification stream open to the NSDB for that
devices, such that future changes of the device are notified to the agent,
updating its internal cache and invalidating any flows that have previously
been established using that device's older configuration.

Some virtual topology metrics are global, whereas others are reported for each
device class, which can be one of the following: `Bridge`, `Chain`, `Host`,
`IPAddrGroup`, `LoadBalancer`, `Mirror`, `Pool`, `PoolHealthMonitorMap`,
`Port`, `PortGroup`, `Router`, `RuleLogger` and `TunnelZone`.

*Global Metrics*

[width="100%",cols="30%,70%",options="header",]
|=======================================================================
|Name |Description
|`VirtualTopologyGauge.devices`
|A gauge for the number of devices stored in the virtual topology cache.
|`VirtualTopologyGauge.observables`
|A gauge for the number of open observable streams that report changes
for the devices stored in the virtual topology cache.
|`VirtualTopologyGauge.cacheHit`
|A gauge for the cache hits when a device was requested by the packet
pipeline when simulating a packet. A cache hit means that the device was
available immediately, and the packet simulation was not interrupted.
|`VirtualTopologyGauge.cacheMiss`
|A gauge for the cache misses when a device was requested by the packet
pipeline when simulating a packet. A cache miss means that the device
needed to be loaded from the NSDB, requiring the packet simulation to be
postponed until the device became available. Cache misses lead to higher
packet processing latencies.
|`VirtualTopologyCounter.deviceUpdate`
|The number of updates the virtual topology caches receives for all
cached devices.
|`VirtualTopologyCounter.deviceError`
|The number of errors the virtual topology caches receives for all cached
devices.
|`VirtualTopologyCounter.deviceComplete`
|A counter for the cached devices that were deleted.
|`VirtualTopologyMeter.deviceUpdate`
|A meter for the device updates received by the virtual topology for the
cached devices.
|`VirtualTopologyMeter.deviceError`
|A meter for the device errors received by the virtual topology for the
cached devices.
|`VirtualTopologyMeter.deviceComplete`
|A meter for the devices deleted from the virtual topology.
|`VirtualTopologyHistogram.deviceLatency`
|A histogram with the latency of loading a device from the NSDB.
|`VirtualTopologyHistogram.deviceLifetime`
|A histogram with the lifetime of a device in the virtual topology cache.
|=======================================================================

== JVM Non-Heap Summary

Shows off-heap memory usage, which consists of mainly buffer pools used for
messages to/from the Netlink layer.

== JVM Heap Summary

Shows per-generation stats. The MidoNet Agent has very specific memory-usage
constraints because it aims for a low memory and CPU footprint. At the same time,
simulations generate a significant amount of short-lived garbage.

* The Eden is configured as the largest generation trying to hold as much
garbage as possible. However, it is likely that it fills up frequently under
high traffic, which may imply that some short-lived objects get promoted to the
old generation and garbage is collected soon afterward.

* The Old Generation is expected to contain a baseline of long-lived objects
that get reused during simulations. An amount of short-lived objects may also be
pushed from the young generation, eventually also filling the old generation and
triggering a GC event that will collect them. This will show as a see-saw
pattern in the "Old used". The see-saw should converge to oscillating between
stable maximum/minimum values on top of the long-lived objects baseline.

** Large spikes indicate higher CPU consumption in GC and are usually associated
with a certain throughput degradation. You may slightly alleviate this by
increasing the size of the Eden.

* JVM GC times: shows the duration of the last garbage collection performed by
the JVM G1 collector. It is closely associated with the see-saw pattern
described above.

** Note that these times do not stop the application completely, because part of
the work is done concurrently. The main impact is in CPU "stolen" from the
agent.

== CPU Usage

Under high traffic, the MidoNet Agent should tend to saturate all CPUs,
reflecting in the graph as high "user" utilization and little or no "idle".
Note that "user" may include other processes, so especially in Gateway Nodes,
you should verify that only the agent is consuming most of CPU time dedicated to
user processes. High "system", "iowait" indicators are clear indication of
high load, excessive context switching, and contention or other problems on the
host.
